# Sepsis-3 Cohort Mortality Prediction Project

A comprehensive machine learning pipeline for predicting 30-day mortality in Sepsis-3 patients, featuring advanced data cleaning, exploratory data analysis, baseline modeling, hyperparameter optimization, and model interpretability.

## ğŸ“‹ Project Overview

This project implements an end-to-end machine learning workflow for sepsis mortality prediction, including:
- **Exploratory Data Analysis (EDA)**: Basic and advanced statistical analysis with visualizations
- **Data Cleaning & Preprocessing**: Clinical domain-aware transformations, missing value handling, feature engineering
- **Baseline Modeling**: Multiple algorithms (Logistic Regression, Random Forest, XGBoost, LightGBM, Stacking)
- **Model Optimization**: Optuna-based hyperparameter tuning, threshold optimization, calibration
- **Model Interpretability**: SHAP analysis, feature importance, subgroup analysis
- **Robust Validation**: Bootstrap confidence intervals, cross-validation, Decision Curve Analysis

---

## ğŸ“ Complete Project Structure

### **Root Level**
```
ML4H/Final/
â”œâ”€â”€ README.md                          # This file - project documentation
â”œâ”€â”€ data/                              # All datasets (raw and processed)
â”œâ”€â”€ scripts/                           # Python scripts for analysis and modeling
â”œâ”€â”€ visualizations/                    # All generated plots and figures
â”œâ”€â”€ logs/                              # Execution logs and statistical outputs
â”œâ”€â”€ reports/                           # Markdown reports and documentation
â”œâ”€â”€ artifacts/                         # Saved preprocessing objects and models
â”œâ”€â”€ outputs/                           # Training outputs (baseline version)
â”œâ”€â”€ outputs_optimized/                 # Training outputs (optimized version)
â””â”€â”€ docs/                              # Project requirements and instructions
```

---

### **ğŸ“‚ data/** - Data Storage Directory

**Purpose**: Stores all datasets in the project lifecycle.

```
data/
â”œâ”€â”€ raw/                                    # Original, unprocessed data
â”‚   â””â”€â”€ sepsis3_cohort_all_features.csv     # Original Sepsis-3 cohort dataset
â”‚                                            # Contains: patient features, target variable (mortality_30d)
â”‚
â””â”€â”€ processed/                              # Cleaned and preprocessed data
    â””â”€â”€ sepsis3_cleaned.csv                 # Fully processed dataset ready for modeling
                                              # Features: outlier treatment, transformations, imputation,
                                              # encoding, feature engineering, standardization
```

**Key Details**:
- `raw/`: Never modified; serves as the single source of truth
- `processed/`: Generated by `step2_data_cleaning.py`; input for all modeling steps
- All data paths are relative to project root in scripts

---

### **ğŸ“‚ scripts/** - Python Code Directory

**Purpose**: Contains all executable Python scripts for the analysis pipeline.

```
scripts/
â”œâ”€â”€ step1_eda.py                        # Basic Exploratory Data Analysis
â”‚                                        # - Loads raw data
â”‚                                        # - Categorizes variables (continuous/categorical)
â”‚                                        # - Generates distribution plots (histograms, violin plots)
â”‚                                        # - Creates correlation matrices
â”‚                                        # - Detects outliers
â”‚                                        # - Outputs summary statistics
â”‚
â”œâ”€â”€ step1_advanced_eda.py               # Advanced Statistical Analysis
â”‚                                        # - Survival vs. death group comparisons (t-tests, boxplots)
â”‚                                        # - Missing value pattern analysis (missingno)
â”‚                                        # - Normality and skewness testing (Shapiro-Wilk, skew)
â”‚                                        # - Continuous variable association trends (logistic smooth curves)
â”‚                                        # - Multivariate interaction analysis (scatter plots with hue)
â”‚                                        # - Generates comprehensive EDA report
â”‚
â”œâ”€â”€ step2_data_cleaning.py              # Data Cleaning & Preprocessing Pipeline
â”‚                                        # - Outlier treatment (Winsorization, clinical caps)
â”‚                                        # - Skewness correction (log1p, QuantileTransformer)
â”‚                                        # - Missing value imputation (median, KNN, missing indicators)
â”‚                                        # - Multicollinearity control (feature removal)
â”‚                                        # - Categorical encoding (OneHotEncoder)
â”‚                                        # - Feature engineering (interactions, binning)
â”‚                                        # - Standardization (StandardScaler)
â”‚                                        # - Quality checks and logging
â”‚
â”œâ”€â”€ step3_modeling.py                   # Baseline Machine Learning Models
â”‚                                        # - Data splitting (70/15/15 stratified)
â”‚                                        # - Baseline models: Logistic Regression, Random Forest,
â”‚                                        #   XGBoost, LightGBM, Stacking Ensemble
â”‚                                        # - Model evaluation (AUC, AUPRC, Accuracy, Recall, F1, Brier)
â”‚                                        # - ROC and PR curve plotting
â”‚                                        # - Model calibration (Platt Scaling, Isotonic Regression)
â”‚                                        # - SHAP interpretability analysis
â”‚                                        # - Subgroup analysis (age, infection source)
â”‚
â”œâ”€â”€ step4_model_optimization.py         # Advanced Model Optimization
â”‚                                        # - Pipeline-based preprocessing (ColumnTransformer)
â”‚                                        # - Threshold optimization (Youden's J, F2, Cost-based)
â”‚                                        # - Optuna hyperparameter search (Bayesian optimization)
â”‚                                        # - Bootstrap confidence intervals (1000 iterations)
â”‚                                        # - Cross-validation level calibration
â”‚                                        # - Subgroup robustness evaluation
â”‚                                        # - Feature interaction analysis
â”‚                                        # - Decision Curve Analysis (DCA)
â”‚
â”œâ”€â”€ step4_optimized_stacking.py         # Optimized Stacking Ensemble
â”‚                                        # - Enhanced base learners (LR, XGBoost, LightGBM, RF)
â”‚                                        # - Meta learner optimization (automatic selection)
â”‚                                        # - Probability calibration (Isotonic, CV=5)
â”‚                                        # - Threshold optimization (F2 maximization, Youden's J)
â”‚                                        # - Bootstrap confidence intervals (1000 iterations)
â”‚                                        # - Comprehensive visualization (ROC, PR, Calibration, DCA)
â”‚                                        # - Clinical-focused optimization (Recall priority)
â”‚
â”œâ”€â”€ main_training_pipeline.py           # Main Orchestration Script
â”‚                                        # - End-to-end pipeline execution
â”‚                                        # - Integrates all steps with progress bars (tqdm)
â”‚                                        # - Unified logging system
â”‚                                        # - Command-line interface (CLI) with argparse
â”‚                                        # - Automatic directory creation
â”‚                                        # - Reproducibility management (random seeds)
â”‚                                        # - Comprehensive result export
â”‚
â”œâ”€â”€ README_PIPELINE.md                  # Documentation for main training pipeline
â”‚                                        # - Usage instructions
â”‚                                        # - Parameter explanations
â”‚                                        # - Output descriptions
â”‚
â””â”€â”€ outputs_optuna/                     # Temporary Optuna study outputs
    â”œâ”€â”€ artifacts/                      # Saved Optuna study objects
    â”œâ”€â”€ logs/                           # Optuna trial logs
    â””â”€â”€ plots/                          # Optuna optimization plots
```

**Execution Order**:
1. `step1_eda.py` â†’ Basic data exploration
2. `step1_advanced_eda.py` â†’ Advanced statistical analysis
3. `step2_data_cleaning.py` â†’ Data preprocessing
4. `step3_modeling.py` OR `main_training_pipeline.py` â†’ Baseline modeling and optimization
5. `step4_optimized_stacking.py` â†’ Enhanced Stacking ensemble (optional, for clinical deployment)

---

### **ğŸ“‚ visualizations/** - Generated Plots Directory

**Purpose**: Stores all visualization outputs from analysis and modeling.

```
visualizations/
â”œâ”€â”€ eda/                                    # Basic EDA Visualizations
â”‚   â”œâ”€â”€ eda_continuous_histograms.png       # Histograms for all continuous variables
â”‚   â”œâ”€â”€ eda_continuous_violin.png           # Violin plots showing distributions
â”‚   â”œâ”€â”€ eda_categorical_frequency.png       # Bar charts for categorical variables
â”‚   â”œâ”€â”€ eda_correlation_matrix.png          # Correlation heatmap between features
â”‚   â””â”€â”€ eda_target_distribution.png         # Distribution of target variable (mortality_30d)
â”‚
â”œâ”€â”€ advanced_eda/                           # Advanced EDA Visualizations
â”‚   â”œâ”€â”€ advanced_eda_survival_comparison.png        # Boxplots: survival vs. death groups
â”‚   â”œâ”€â”€ advanced_eda_missing_pattern.png            # Missingno matrix plot
â”‚   â”œâ”€â”€ advanced_eda_missing_correlation.png        # Heatmap of missing value correlations
â”‚   â”œâ”€â”€ advanced_eda_skewness_analysis.png          # Skewness before/after transformations
â”‚   â”œâ”€â”€ advanced_eda_logistic_association.png       # Logistic regression smooth curves
â”‚   â””â”€â”€ advanced_eda_multivariate_interaction.png   # Scatter plots with mortality hue
â”‚
â””â”€â”€ modeling/                               # Model Evaluation Visualizations
    â”œâ”€â”€ roc_pr_curves.png                  # ROC and PR curves for all models
    â”œâ”€â”€ calibration_plot.png               # Calibration curves (reliability diagrams)
    â”œâ”€â”€ dca_plot.png                       # Decision Curve Analysis plot
    â”œâ”€â”€ optimized_stacking_roc.png         # Optimized Stacking ROC curve
    â”œâ”€â”€ optimized_stacking_pr.png          # Optimized Stacking PR curve
    â”œâ”€â”€ optimized_stacking_calibration.png # Optimized Stacking calibration curve
    â”œâ”€â”€ optimized_stacking_dca.png         # Optimized Stacking DCA plot
    â””â”€â”€ [Additional SHAP plots if generated]
```

**Visualization Format**:
- All plots: 300 DPI PNG format, suitable for publications
- Consistent styling: English labels, clear titles, legends
- Color schemes: Colorblind-friendly palettes

---

### **ğŸ“‚ logs/** - Execution Logs and Statistics

**Purpose**: Contains execution logs, statistical outputs, and intermediate results.

```
logs/
â”œâ”€â”€ eda/                                    # EDA Statistical Outputs
â”‚   â”œâ”€â”€ eda_summary_statistics.csv          # Descriptive statistics (mean, std, min, max, etc.)
â”‚   â”œâ”€â”€ advanced_eda_survival_statistics.csv # T-test results: survival vs. death groups
â”‚   â””â”€â”€ advanced_eda_normality_analysis.csv  # Normality tests and skewness measures
â”‚
â”œâ”€â”€ cleaning/                               # Data Cleaning Logs
â”‚   â”œâ”€â”€ cleaning.log                        # Detailed execution log (logging module)
â”‚   â”œâ”€â”€ cleaning_log_outliers.csv           # Outlier detection and treatment records
â”‚   â”œâ”€â”€ cleaning_log_transformations.csv    # Transformation effects (skewness changes)
â”‚   â”œâ”€â”€ cleaning_log_missing_values.csv     # Missing value imputation records
â”‚   â””â”€â”€ cleaning_comparison_stats.csv       # Before/after cleaning statistics comparison
â”‚
â””â”€â”€ modeling/                               # Modeling Execution Logs
    â”œâ”€â”€ optimized_stacking_performance.csv      # Optimized Stacking performance metrics
    â”œâ”€â”€ optimized_stacking_thresholds.csv       # Threshold optimization results
    â”œâ”€â”€ optimized_stacking_bootstrap_ci.csv     # Bootstrap confidence intervals
    â””â”€â”€ [Additional modeling logs if generated]
```

**Logging Levels**:
- `INFO`: Normal execution flow
- `WARNING`: Non-critical issues
- `ERROR`: Critical failures

---

### **ğŸ“‚ reports/** - Documentation and Reports

**Purpose**: Markdown documentation files explaining analysis results and methodology.

```
reports/
â”œâ”€â”€ advanced_eda_summary_report.md          # Comprehensive EDA findings
â”‚                                            # - Key variable associations
â”‚                                            # - Missing data patterns
â”‚                                            # - Distribution characteristics
â”‚                                            # - Statistical significance tests
â”‚
â”œâ”€â”€ data_cleaning_report.md                 # Data cleaning methodology and results
â”‚                                            # - Transformation rationale
â”‚                                            # - Missing value handling strategy
â”‚                                            # - Feature engineering details
â”‚
â”œâ”€â”€ data_cleaning_enhancements.md           # Enhanced cleaning improvements
â”‚                                            # - Clinical physiological caps
â”‚                                            # - Missing indicators
â”‚                                            # - Advanced transformations
â”‚                                            # - Statistical impact analysis
â”‚
â”œâ”€â”€ file_organization_index.md              # Complete file index and descriptions
â”‚                                            # - Directory structure
â”‚                                            # - File purposes
â”‚                                            # - Generation scripts
â”‚
â””â”€â”€ QUICK_REFERENCE.md                      # Quick reference guide
                                             # - Common commands
                                             # - File locations
                                             # - Troubleshooting tips
```

---

### **ğŸ“‚ artifacts/** - Preprocessing Objects

**Purpose**: Stores fitted preprocessing transformers and feature mappings for reproducibility.

```
artifacts/
â”œâ”€â”€ standard_scaler.pkl                     # Fitted StandardScaler object
â”‚                                            # - Used for standardizing continuous features
â”‚                                            # - Can be loaded to transform new data
â”‚                                            # - Generated by step2_data_cleaning.py
â”‚
â”œâ”€â”€ feature_list.json                       # Feature mapping and metadata
â”‚                                            # - Original feature names
â”‚                                            # - Transformed feature names
â”‚                                            # - Feature categories
â”‚                                            # - Encoding mappings
â”‚
â”œâ”€â”€ optimized_stacking_model.pkl            # Optimized Stacking Ensemble Model
â”‚                                            # - Calibrated Stacking model (4 base learners)
â”‚                                            # - Generated by step4_optimized_stacking.py
â”‚                                            # - Ready for deployment and prediction
â”‚
â””â”€â”€ optimized_stacking_config.json          # Optimized Stacking Configuration
                                              # - Model architecture details
                                              # - Hyperparameters
                                              # - Optimal threshold
                                              # - Calibration settings
```

**Usage**: These artifacts enable consistent preprocessing for:
- New data prediction
- Model deployment
- Reproducibility verification

---

### **ğŸ“‚ outputs/** - Model Training Outputs (Baseline)

**Purpose**: Stores results from baseline model training runs (before data cleaning optimizations).

```
outputs/
â”œâ”€â”€ artifacts/                              # Saved Model Artifacts
â”‚   â”œâ”€â”€ best_sepsis_model.pkl              # Trained best model (joblib format)
â”‚   â””â”€â”€ optuna_best_params.json            # Optimized hyperparameters (JSON format)
â”‚
â”œâ”€â”€ logs/                                   # Model Performance Metrics
â”‚   â”œâ”€â”€ train.log                          # Training execution log
â”‚   â”œâ”€â”€ model_performance_summary.csv      # Comprehensive metrics (AUC, AUPRC, Brier, etc.)
â”‚   â”œâ”€â”€ bootstrap_confidence_intervals.csv # 95% CI for metrics (1000 bootstrap iterations)
â”‚   â”œâ”€â”€ threshold_optimization_report.csv  # Optimal thresholds (Youden, F2, Cost-based)
â”‚   â””â”€â”€ subgroup_performance_table.csv     # Performance across subgroups (age, infection source)
â”‚
â””â”€â”€ plots/                                  # Model Evaluation Visualizations
    â”œâ”€â”€ roc_pr_curves.png                  # ROC and PR curves for all models
    â”œâ”€â”€ calibration_plot.png               # Model calibration curves
    â””â”€â”€ dca_plot.png                       # Decision Curve Analysis plot
```

**Baseline Results**:
- Best Model: Stacking Ensemble
- AUC: ~0.80
- AUPRC: ~0.58
- Brier Score: ~0.14

---

### **ğŸ“‚ outputs_optimized/** - Model Training Outputs (Optimized)

**Purpose**: Stores results from model training using optimized data cleaning pipeline.

```
outputs_optimized/
â”œâ”€â”€ artifacts/                              # Saved Model Artifacts
â”‚   â”œâ”€â”€ best_sepsis_model.pkl              # Trained best model with optimized preprocessing
â”‚   â””â”€â”€ optuna_best_params.json            # Optimized hyperparameters
â”‚
â”œâ”€â”€ logs/                                   # Model Performance Metrics
â”‚   â”œâ”€â”€ train.log                          # Training execution log
â”‚   â”œâ”€â”€ model_performance_summary.csv      # Performance metrics comparison
â”‚   â”œâ”€â”€ bootstrap_confidence_intervals.csv # Bootstrap CI for optimized model
â”‚   â”œâ”€â”€ threshold_optimization_report.csv  # Optimal thresholds
â”‚   â””â”€â”€ subgroup_performance_table.csv     # Subgroup performance analysis
â”‚
â””â”€â”€ plots/                                  # Model Evaluation Visualizations
    â”œâ”€â”€ roc_pr_curves.png                  # ROC/PR curves
    â”œâ”€â”€ calibration_plot.png               # Calibration curves
    â””â”€â”€ dca_plot.png                       # DCA plot
```

**Optimized Results**:
- Best Model: XGBoost_Optimized
- AUC: ~0.80 (stable performance)
- AUPRC: ~0.58 (slight improvement)
- Brier Score: ~0.14 (stable)
- **Key Improvement**: Enhanced data quality, distribution normalization, robustness

---

### **ğŸ“‚ docs/** - Project Documentation

**Purpose**: Contains original project requirements and specifications.

```
docs/
â””â”€â”€ instruciton.txt                        # Original project prompt and requirements
                                           # - Complete task specifications
                                           # - Step-by-step instructions
                                           # - Evaluation criteria
                                           # - Output requirements
```

---

## ğŸš€ Quick Start Guide

### Prerequisites

```bash
# Required Python packages (install via pip)
pandas numpy scikit-learn matplotlib seaborn
xgboost lightgbm optuna shap missingno
tqdm scipy joblib
```

### Step-by-Step Execution

#### 1. **Basic Exploratory Data Analysis**
```bash
cd scripts
python step1_eda.py
```
**Outputs**:
- Visualizations: `visualizations/eda/*.png`
- Statistics: `logs/eda/eda_summary_statistics.csv`

#### 2. **Advanced Exploratory Data Analysis**
```bash
python step1_advanced_eda.py
```
**Outputs**:
- Advanced visualizations: `visualizations/advanced_eda/*.png`
- Statistical tests: `logs/eda/advanced_eda_*.csv`
- Report: `reports/advanced_eda_summary_report.md`

#### 3. **Data Cleaning & Preprocessing**
```bash
python step2_data_cleaning.py
```
**Outputs**:
- Cleaned dataset: `data/processed/sepsis3_cleaned.csv`
- Preprocessing artifacts: `artifacts/*.pkl`, `artifacts/*.json`
- Cleaning logs: `logs/cleaning/*.csv`, `logs/cleaning/cleaning.log`

#### 4. **Model Training (Integrated Pipeline)**
```bash
python main_training_pipeline.py \
    --data ../data/processed/sepsis3_cleaned.csv \
    --out_dir ../outputs_optimized \
    --seed 42 \
    --optuna_trials 80 \
    --cv_folds 5
```

**Or run individual steps**:
```bash
# Baseline modeling
python step3_modeling.py

# Model optimization
python step4_model_optimization.py

# Optimized Stacking Ensemble (Enhanced version)
python step4_optimized_stacking.py
```

**Outputs**:
- Model artifacts: `outputs_optimized/artifacts/*.pkl`, `artifacts/optimized_stacking_model.pkl`
- Performance metrics: `outputs_optimized/logs/*.csv`, `logs/modeling/optimized_stacking_*.csv`
- Visualizations: `outputs_optimized/plots/*.png`, `visualizations/modeling/optimized_stacking_*.png`
- Training log: `outputs_optimized/logs/train.log`

---

## ğŸ“Š Key Findings

### Dataset Characteristics
- **Total Patients**: 20,391
- **Mortality Rate**: 23.06% (4,703 deaths)
- **Features**: 30+ features after preprocessing
- **Missing Values**: 0% after cleaning pipeline

### Model Performance (Optimized)

#### Main Training Pipeline Results
- **Best Model**: XGBoost_Optimized / Stacking_Optimized
- **AUC**: 0.8033 (95% CI: [0.7823, 0.8175])
- **AUPRC**: 0.5784 (95% CI: [0.5438, 0.6155])
- **Brier Score**: 0.1375 (95% CI: [0.1299, 0.1443])

#### Optimized Stacking Ensemble Results
- **Best Model**: Optimized Stacking (4 base learners: LR, XGBoost, LightGBM, RF)
- **AUC**: 0.8015 (95% CI: [0.7845, 0.8190])
- **AUPRC**: 0.5801 (95% CI: [0.5438, 0.6155])
- **Recall**: 0.8994 (F2-optimized threshold: 0.1166)
- **F2-Score**: 0.6776
- **Brier Score**: 0.1375 (95% CI: [0.1299, 0.1443])
- **Key Improvement**: +22.12% Recall improvement, 26.03% Brier Score reduction via calibration

### Data Quality Improvements
- **Outlier Treatment**: 46 extreme values capped using clinical thresholds
- **Skewness Reduction**: Average skewness reduced from 2-6 to <1
- **Missing Indicators**: 2 binary features capturing missingness signals
- **Distribution Normalization**: QuantileTransformer applied to key variables

### Key Predictors (Top Features)
- SOFA score total
- Lactate maximum (24h)
- Age
- Creatinine maximum
- Interaction terms (SOFA Ã— Lactate, SOFA Ã— Age)

---

## ğŸ”¬ Technical Details

### Data Cleaning Pipeline
1. **Clinical Caps**: Lactate (<20.0), Creatinine (<20.0), INR (<20.0), Urine Output (<15000 mL)
2. **Outlier Treatment**: Winsorization (1%-99%) for selected variables
3. **Skewness Correction**: 
   - Log1p transformation for: WBC, Creatinine, Lactate, INR, Anion Gap
   - QuantileTransformer for: Lactate, WBC, Creatinine
4. **Missing Value Imputation**:
   - <10% missing: Median imputation
   - 10-30% missing: KNN Imputation (grouped by biology)
   - >40% missing: Missing indicators created
5. **Feature Engineering**:
   - Interaction terms: `sofa_total Ã— lactate_max_24h`, `sofa_total Ã— age`
   - Binning: Lactate (quartiles), Age (clinical thresholds)
6. **Standardization**: StandardScaler for all continuous features

### Modeling Approach
- **Baseline Models**: Logistic Regression, Random Forest, XGBoost, LightGBM, Stacking
- **Hyperparameter Optimization**: Optuna (TPE Sampler, 80 trials, nested CV)
- **Stacking Enhancement**: 4 base learners (LR, XGBoost, LightGBM, RandomForest) with meta-learner optimization
- **Cross-Validation**: Stratified 5-fold CV
- **Threshold Optimization**: Youden's J, F2-score (Recall priority), Cost-based
- **Calibration**: Platt Scaling, Isotonic Regression, CalibratedClassifierCV (CV-level)
- **Interpretability**: SHAP (TreeExplainer), Feature Importance, Subgroup Analysis
- **Robustness**: Bootstrap CI (1000 iterations), Subgroup evaluation, Decision Curve Analysis

---

## ğŸ“š Documentation

For more detailed information, see:

- **File Organization**: `reports/file_organization_index.md`
- **Quick Reference**: `reports/QUICK_REFERENCE.md`
- **Data Cleaning Details**: `reports/data_cleaning_report.md`
- **Cleaning Enhancements**: `reports/data_cleaning_enhancements.md`
- **Pipeline Usage**: `scripts/README_PIPELINE.md`
- **Optimized Stacking Guide**: `scripts/README_OPTIMIZED_STACKING.md`

---

## ğŸ”„ Workflow Summary

```
Raw Data (data/raw/)
    â†“
[step1_eda.py] â†’ Basic Exploration
    â†“
[step1_advanced_eda.py] â†’ Advanced Analysis
    â†“
[step2_data_cleaning.py] â†’ Preprocessing
    â†“
Cleaned Data (data/processed/)
    â†“
[main_training_pipeline.py] â†’ Modeling & Optimization
    â†“
Results (outputs_optimized/)
    â”œâ”€â”€ Trained Models
    â”œâ”€â”€ Performance Metrics
    â””â”€â”€ Visualizations
```

---

## ğŸ“ Notes

- All scripts use English output and logging
- Random seed fixed at 42 for reproducibility
- Progress bars (tqdm) provide execution feedback
- Comprehensive logging to files and console
- All visualizations saved at 300 DPI for publication quality

---

## ğŸ“§ Contact & Support

For questions or issues, refer to:
- Project documentation in `reports/`
- Script docstrings for code-level details
- Execution logs in `logs/` for debugging

---

**Last Updated**: 2025-11-04  
**Python Version**: 3.10+  
**Status**: âœ… Production Ready

**Recent Updates**:
- Added optimized Stacking ensemble with 4 base learners (November 2025)
- Enhanced threshold optimization with F2 maximization for clinical recall priority
- Improved probability calibration with CV-level Isotonic regression
- Expanded visualization suite with DCA and calibration curves
